# AI Textbook Processor

A modular, AI-powered educational content processing system that extracts, validates, and generates educational materials from PDFs and images.

## ğŸ—ï¸ Architecture

The project follows a clean, modular architecture with clear separation of concerns:

```
ai-textbook-processor/
â”œâ”€â”€ agent/                    # LangGraph Studio integration
â”‚   â”œâ”€â”€ app.py               # Studio entry point
â”‚   â”œâ”€â”€ graph.py             # Pure LangGraph workflow
â”‚   â””â”€â”€ langgraph.json       # Studio configuration
â”œâ”€â”€ core/                    # Core business logic
â”‚   â”œâ”€â”€ tools.py             # LLM functions only
â”‚   â”œâ”€â”€ helpers.py           # Utility functions
â”‚   â”œâ”€â”€ extractors.py        # Content extraction
â”‚   â”œâ”€â”€ validators.py        # Validation functions
â”‚   â””â”€â”€ generators.py        # Content generation
â”œâ”€â”€ models/                  # Data models
â”‚   â”œâ”€â”€ schemas.py           # Pydantic models
â”‚   â””â”€â”€ state.py             # LangGraph state
â”œâ”€â”€ services/                # Business services
â”‚   â”œâ”€â”€ pdf_service.py       # PDF processing
â”‚   â”œâ”€â”€ image_service.py     # Image processing
â”‚   â””â”€â”€ content_service.py   # Main processing service
â”œâ”€â”€ api/                     # API layer
â”‚   â”œâ”€â”€ routes.py            # FastAPI routes
â”‚   â””â”€â”€ server.py            # Minimal server
â”œâ”€â”€ config/                  # Configuration
â”‚   â”œâ”€â”€ settings.py          # App settings
â”‚   â””â”€â”€ logging.py           # Logging config
â”œâ”€â”€ utils/                   # Utilities
â”‚   â”œâ”€â”€ parsers.py           # Content parsing
â”‚   â””â”€â”€ formatters.py        # Output formatting
â”œâ”€â”€ graph.py                 # Clean LangGraph workflow
â””â”€â”€ main.py                  # Minimal entry point
```

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Clone the repository
git clone <repository-url>
cd ai-textbook-processor

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure Environment Variables

Create a `.env` file:

```env
AZURE_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_API_KEY=your-api-key
AZURE_DEPLOYMENT_NAME=gpt-4
LOG_LEVEL=INFO
```

### 3. Run the Application

#### Option A: Direct Processing
```bash
python main.py
```

#### Option B: API Server
```bash
uvicorn api.server:app --host 0.0.0.0 --port 8000
```

#### Option C: LangGraph Studio
```bash
cd agent
langgraph dev
```

## ğŸ“‹ Features

### âœ… Content Processing
- **PDF Text Extraction**: Extract text from PDF files using Tika
- **Image Processing**: Process images with vision AI
- **Single Source Only**: Process either images OR PDF (not mixed sources)

### âœ… Content Validation
- **Grade Level Check**: Ensure content is appropriate for target grade
- **Safety Analysis**: Verify content is safe for students
- **Relevance Check**: Confirm content matches subject/chapter

### âœ… Educational Content Generation
- **Study Notes**: Comprehensive study materials
- **Fill-in-the-Blanks**: Interactive exercises
- **Match-the-Following**: Matching exercises
- **Subjective Q&A**: Thought-provoking questions

### âœ… API Endpoints
- `POST /api/v1/process`: Process files (PDF/images)
- `POST /api/v1/process-text`: Process text content
- `GET /api/v1/health`: Health check

## ğŸ”§ Usage Examples

### Direct API Call
```python
from services.content_service import ContentProcessingService

service = ContentProcessingService()

# Process PDF only
result = service.process_content(
    standard="Class 10",
    subject="Mathematics",
    chapter="Algebra",
    pdf_path="math_chapter.pdf"
)

# OR process images only
result = service.process_content(
    standard="Class 10",
    subject="Mathematics",
    chapter="Algebra",
    image_paths=["image1.jpg", "image2.png"]
)
```

### API Endpoint
```bash
# Process PDF only
curl -X POST "http://localhost:8000/api/v1/process" \
  -F "standard=Class 10" \
  -F "subject=Mathematics" \
  -F "chapter=Algebra" \
  -F "pdf_file=@math_chapter.pdf"

# OR process images only
curl -X POST "http://localhost:8000/api/v1/process" \
  -F "standard=Class 10" \
  -F "subject=Mathematics" \
  -F "chapter=Algebra" \
  -F "image_files=@image1.jpg" \
  -F "image_files=@image2.png"
```

### LangGraph Workflow
```python
from graph import workflow

# Create initial state
state = {
    "messages": [
        {"role": "system", "content": "You are an educational content processor..."},
        {"role": "user", "content": "Educational content to process: ..."}
    ],
    "processing_steps": []
}

# Run workflow
result = workflow.invoke(state)
```

## ğŸ›ï¸ Architecture Principles

### 1. **Single Responsibility**
- Each file has one clear purpose
- `tools.py` contains only LLM functions
- `helpers.py` contains only utility functions
- `graph.py` contains only LangGraph workflow

### 2. **Separation of Concerns**
- **Core**: Business logic and LLM interactions
- **Services**: File processing and content management
- **API**: HTTP interface and request handling
- **Models**: Data validation and state management

### 3. **Modularity**
- Easy to test individual components
- Simple to extend with new features
- Clear dependencies between modules

### 4. **Clean Code**
- Minimal `main.py` - just entry point
- Descriptive function names
- Comprehensive error handling
- Proper logging throughout

## ğŸ§ª Testing

```bash
# Run tests
pytest

# Format code
black .

# Lint code
flake8 .
```

## ğŸ“Š Monitoring

The application includes comprehensive logging:
- Token usage tracking for cost monitoring
- Processing step tracking
- Error logging with context
- Performance metrics

## ğŸ”’ Security

- Input validation on all endpoints
- File type validation
- Size limits on uploads
- Secure environment variable handling

## ğŸš€ Deployment

### Docker
```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["uvicorn", "api.server:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Environment Variables
- `AZURE_ENDPOINT`: Azure OpenAI endpoint
- `AZURE_API_KEY`: Azure OpenAI API key
- `AZURE_DEPLOYMENT_NAME`: Model deployment name
- `LOG_LEVEL`: Logging level (INFO, DEBUG, etc.)

## ğŸ¤ Contributing

1. Follow the modular architecture
2. Add tests for new features
3. Update documentation
4. Use proper logging
5. Follow PEP 8 style guidelines

## ğŸ“„ License

This project is licensed under the MIT License.
